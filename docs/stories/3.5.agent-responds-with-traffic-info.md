# <!-- Powered by BMADâ„¢ Core -->
# Story 3.5: Agent Responds with Traffic Info

## Status
Draft

## Story
**As a** user,
**I want** to ask "how is the traffic to the station?" and receive a text response describing the current traffic conditions,
**so that** I can get real-time information.

## Acceptance Criteria
1. When the `agent-service` detects a `check_traffic` intent, it calls the external traffic API service.
2. The service formats the data from the traffic API into a human-readable string.
3. The `POST /api/v1/agent/query` endpoint returns a JSON object containing the formatted response string.
4. The mobile app displays the agent's response in the chat history after the user sends a query.

## Tasks / Subtasks

### Backend (`agent-service`)
- [ ] In the main agent service logic, add a step after processing the NLP result. (AC: #1)
- [ ] If the intent is `check_traffic`, call the `trafficService.getTrafficData` function, passing any location entities. (AC: #1)
- [ ] Create a utility function to format the simplified traffic data into a natural language sentence (e.g., "Traffic is currently heavy."). (AC: #2)
- [ ] The `POST /api/v1/agent/query` endpoint should return a JSON response like `{ "response": "..." }`. (AC: #3)
- [ ] Implement a fallback response if the traffic service fails or returns no data. (AC: #2)

### Frontend (`AgentChatScreen.tsx`)
- [ ] Create a client-side service function to call the `POST /api/v1/agent/query` endpoint. (AC: #4)
- [ ] When a user sends a message, add their message to the chat history and immediately call this service function. (AC: #4)
- [ ] Add a loading indicator (e.g., a "... is typing" message) to the chat while waiting for the API response. (AC: #4)
- [ ] When the API call succeeds, add the agent's response from the API to the chat history and remove the loading indicator. (AC: #4)

## Dev Notes
This story connects all the pieces of the agent MVP. The data flow is now end-to-end: from the user's query in the UI to the backend services and back to the UI.

- **End-to-End Flow:** UI -> Agent API -> NLP Service -> Traffic Service -> Response Formatter -> UI.
- **Response Formatting:** The logic to convert structured data (from the traffic service) into a sentence should be simple for now, but encapsulated in its own function for future enhancement.
- **Frontend UX:** Displaying a loading indicator is important for good user experience, as the backend may take a second or two to process the request.

### Testing
- **Backend End-to-End Test:** Write an integration test for the `POST /api/v1/agent/query` endpoint. In the test, mock both the `nlpService` (to return a `check_traffic` intent) and the `trafficService` (to return mock traffic data). Send a query to the endpoint and assert that the final HTTP response contains the correctly formatted natural language string.
- **Frontend Integration Test:** Test the `AgentChatScreen`. Mock the agent API endpoint. Simulate a user sending a message. Verify that the user's message appears, a loading state is shown, the API is called, and finally, the agent's mock response is displayed in the chat history.

## Change Log
| Date | Version | Description | Author |
| :--- | :--- | :--- | :--- |
| 2025-10-18 | 1.0 | Initial draft of the story. | Sarah (PO) |
