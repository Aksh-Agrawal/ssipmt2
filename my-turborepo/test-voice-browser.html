<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        button {
            padding: 15px 30px;
            font-size: 16px;
            margin: 10px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            background: #2196F3;
            color: white;
        }
        button:hover {
            background: #1976D2;
        }
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        .status {
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
            background: #e3f2fd;
        }
        .error {
            background: #ffebee;
            color: #c62828;
        }
        .success {
            background: #e8f5e9;
            color: #2e7d32;
        }
        .logs {
            background: #263238;
            color: #aed581;
            padding: 15px;
            border-radius: 5px;
            margin-top: 20px;
            max-height: 300px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 14px;
        }
        .audio-level {
            height: 20px;
            background: #4caf50;
            border-radius: 3px;
            transition: width 0.1s;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Voice Assistant Test</h1>
        <p>This is a simple test page to verify the voice pipeline works.</p>
        
        <div>
            <button id="testMic" onclick="testMicrophone()">1Ô∏è‚É£ Test Microphone</button>
            <button id="recordBtn" onclick="startRecording()" disabled>2Ô∏è‚É£ Record & Send</button>
            <button id="stopBtn" onclick="stopRecording()" disabled>‚èπÔ∏è Stop</button>
        </div>

        <div id="status" class="status">Status: Ready</div>
        
        <div style="margin: 15px 0;">
            <strong>Audio Level:</strong>
            <div style="background: #ddd; height: 20px; border-radius: 3px; overflow: hidden;">
                <div id="audioLevel" class="audio-level" style="width: 0%"></div>
            </div>
        </div>

        <div id="response" style="margin-top: 20px;"></div>

        <div class="logs" id="logs">
üìã Logs will appear here...
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let analyser;
        let stream;

        function log(message, type = 'info') {
            const logsDiv = document.getElementById('logs');
            const timestamp = new Date().toLocaleTimeString();
            const icon = type === 'error' ? '‚ùå' : type === 'success' ? '‚úÖ' : '‚ÑπÔ∏è';
            logsDiv.innerHTML += `\n${icon} [${timestamp}] ${message}`;
            logsDiv.scrollTop = logsDiv.scrollHeight;
        }

        function updateStatus(message, type = 'info') {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = message;
            statusDiv.className = 'status';
            if (type === 'error') statusDiv.classList.add('error');
            if (type === 'success') statusDiv.classList.add('success');
        }

        async function testMicrophone() {
            try {
                log('Testing microphone access...');
                updateStatus('üé§ Requesting microphone permission...');
                
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                    }
                });
                
                log('‚úÖ Microphone access granted!', 'success');
                updateStatus('‚úÖ Microphone is working! You can now record.', 'success');
                
                // Setup audio level monitoring
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);
                analyser.fftSize = 512;
                
                monitorAudioLevel();
                
                document.getElementById('recordBtn').disabled = false;
                
            } catch (error) {
                log(`‚ùå Microphone error: ${error.message}`, 'error');
                updateStatus(`‚ùå Error: ${error.message}`, 'error');
            }
        }

        function monitorAudioLevel() {
            if (!analyser) return;
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            
            function update() {
                analyser.getByteFrequencyData(dataArray);
                const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                const level = Math.min(100, (average / 128) * 100);
                
                document.getElementById('audioLevel').style.width = level + '%';
                
                if (level > 10) {
                    log(`üé§ Audio detected! Level: ${level.toFixed(0)}%`);
                }
                
                requestAnimationFrame(update);
            }
            update();
        }

        async function startRecording() {
            try {
                log('üéôÔ∏è Starting recording...');
                updateStatus('üéôÔ∏è Recording... Speak now!');
                
                audioChunks = [];
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        log(`üìä Audio chunk received: ${event.data.size} bytes`);
                    }
                };
                
                mediaRecorder.onstop = async () => {
                    log('‚èπÔ∏è Recording stopped, processing...');
                    await sendAudioToAPI();
                };
                
                mediaRecorder.start();
                document.getElementById('recordBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                
                log('‚úÖ Recording started successfully', 'success');
                
            } catch (error) {
                log(`‚ùå Recording error: ${error.message}`, 'error');
                updateStatus(`‚ùå Error: ${error.message}`, 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                log('‚èπÔ∏è Stopping recording...');
                mediaRecorder.stop();
                document.getElementById('recordBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
            }
        }

        async function sendAudioToAPI() {
            try {
                updateStatus('üì§ Sending audio to server...');
                log('üì§ Creating audio blob...');
                
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm;codecs=opus' });
                log(`üìä Audio blob size: ${audioBlob.size} bytes`);
                
                if (audioBlob.size < 1000) {
                    throw new Error('Audio too short or empty. Please speak longer.');
                }
                
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.webm');
                formData.append('language', 'en');
                
                log('üåê Sending to /api/voice-chat endpoint...');
                updateStatus('‚è≥ Processing (STT ‚Üí AI ‚Üí TTS)...');
                
                const response = await fetch('http://localhost:3000/api/voice-chat', {
                    method: 'POST',
                    body: formData,
                });
                
                log(`üì® Response status: ${response.status}`);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Server error: ${response.status} - ${errorText}`);
                }
                
                const result = await response.json();
                log('‚úÖ Response received!', 'success');
                
                // Display results
                const responseDiv = document.getElementById('response');
                responseDiv.innerHTML = `
                    <div style="background: #e8f5e9; padding: 15px; border-radius: 5px; margin-top: 15px;">
                        <h3>üìù Transcription:</h3>
                        <p><strong>"${result.transcription}"</strong></p>
                        
                        <h3>ü§ñ AI Response:</h3>
                        <p>${result.response}</p>
                        
                        ${result.audioResponse ? '<p>üîä <em>Playing audio response...</em></p>' : ''}
                    </div>
                `;
                
                log(`üìù Transcription: ${result.transcription}`);
                log(`ü§ñ AI Response: ${result.response.substring(0, 100)}...`);
                
                // Play audio response if available
                if (result.audioResponse) {
                    log('üîä Playing TTS audio...');
                    const audioData = Uint8Array.from(atob(result.audioResponse), c => c.charCodeAt(0));
                    const audioBlob = new Blob([audioData], { type: 'audio/mpeg' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    
                    audio.onended = () => {
                        log('‚úÖ Audio playback complete', 'success');
                        updateStatus('‚úÖ Complete! You can record again.', 'success');
                    };
                    
                    audio.play();
                } else {
                    updateStatus('‚úÖ Complete! (No audio generated)', 'success');
                }
                
            } catch (error) {
                log(`‚ùå API error: ${error.message}`, 'error');
                updateStatus(`‚ùå Error: ${error.message}`, 'error');
            }
        }
    </script>
</body>
</html>
